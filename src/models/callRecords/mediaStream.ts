// tslint:disable
// eslint-disable
// Generated by Microsoft Kiota
import { AudioCodec } from './audioCodec';
import { MediaStreamDirection } from './mediaStreamDirection';
import { VideoCodec } from './videoCodec';
import { type AdditionalDataHolder, type Duration, type Parsable, type ParseNode, type SerializationWriter } from '@microsoft/kiota-abstractions';

export function createMediaStreamFromDiscriminatorValue(parseNode: ParseNode | undefined) {
    if(!parseNode) throw new Error("parseNode cannot be undefined");
    return deserializeIntoMediaStream;
}
export function deserializeIntoMediaStream(mediaStream: MediaStream | undefined = {} as MediaStream) : Record<string, (node: ParseNode) => void> {
    return {
        "audioCodec": n => { mediaStream.audioCodec = n.getEnumValue<AudioCodec>(AudioCodec); },
        "averageAudioDegradation": n => { mediaStream.averageAudioDegradation = n.getNumberValue(); },
        "averageAudioNetworkJitter": n => { mediaStream.averageAudioNetworkJitter = n.getDurationValue(); },
        "averageBandwidthEstimate": n => { mediaStream.averageBandwidthEstimate = n.getNumberValue(); },
        "averageFreezeDuration": n => { mediaStream.averageFreezeDuration = n.getDurationValue(); },
        "averageJitter": n => { mediaStream.averageJitter = n.getDurationValue(); },
        "averagePacketLossRate": n => { mediaStream.averagePacketLossRate = n.getNumberValue(); },
        "averageRatioOfConcealedSamples": n => { mediaStream.averageRatioOfConcealedSamples = n.getNumberValue(); },
        "averageReceivedFrameRate": n => { mediaStream.averageReceivedFrameRate = n.getNumberValue(); },
        "averageRoundTripTime": n => { mediaStream.averageRoundTripTime = n.getDurationValue(); },
        "averageVideoFrameLossPercentage": n => { mediaStream.averageVideoFrameLossPercentage = n.getNumberValue(); },
        "averageVideoFrameRate": n => { mediaStream.averageVideoFrameRate = n.getNumberValue(); },
        "averageVideoPacketLossRate": n => { mediaStream.averageVideoPacketLossRate = n.getNumberValue(); },
        "endDateTime": n => { mediaStream.endDateTime = n.getDateValue(); },
        "isAudioForwardErrorCorrectionUsed": n => { mediaStream.isAudioForwardErrorCorrectionUsed = n.getBooleanValue(); },
        "lowFrameRateRatio": n => { mediaStream.lowFrameRateRatio = n.getNumberValue(); },
        "lowVideoProcessingCapabilityRatio": n => { mediaStream.lowVideoProcessingCapabilityRatio = n.getNumberValue(); },
        "maxAudioNetworkJitter": n => { mediaStream.maxAudioNetworkJitter = n.getDurationValue(); },
        "maxJitter": n => { mediaStream.maxJitter = n.getDurationValue(); },
        "maxPacketLossRate": n => { mediaStream.maxPacketLossRate = n.getNumberValue(); },
        "maxRatioOfConcealedSamples": n => { mediaStream.maxRatioOfConcealedSamples = n.getNumberValue(); },
        "maxRoundTripTime": n => { mediaStream.maxRoundTripTime = n.getDurationValue(); },
        "@odata.type": n => { mediaStream.odataType = n.getStringValue(); },
        "packetUtilization": n => { mediaStream.packetUtilization = n.getNumberValue(); },
        "postForwardErrorCorrectionPacketLossRate": n => { mediaStream.postForwardErrorCorrectionPacketLossRate = n.getNumberValue(); },
        "rmsFreezeDuration": n => { mediaStream.rmsFreezeDuration = n.getDurationValue(); },
        "startDateTime": n => { mediaStream.startDateTime = n.getDateValue(); },
        "streamDirection": n => { mediaStream.streamDirection = n.getEnumValue<MediaStreamDirection>(MediaStreamDirection); },
        "streamId": n => { mediaStream.streamId = n.getStringValue(); },
        "videoCodec": n => { mediaStream.videoCodec = n.getEnumValue<VideoCodec>(VideoCodec); },
        "wasMediaBypassed": n => { mediaStream.wasMediaBypassed = n.getBooleanValue(); },
    }
}
export interface MediaStream extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Codec name used to encode audio for transmission on the network. Possible values are: unknown, invalid, cn, pcma, pcmu, amrWide, g722, g7221, g7221c, g729, multiChannelAudio, muchv2, opus, satin, satinFullband, rtAudio8, rtAudio16, silk, silkNarrow, silkWide, siren, xmsRta, unknownFutureValue.
     */
    audioCodec?: AudioCodec;
    /**
     * Average Network Mean Opinion Score degradation for stream. Represents how much the network loss and jitter has impacted the quality of received audio.
     */
    averageAudioDegradation?: number;
    /**
     * Average jitter for the stream computed as specified in [RFC 3550][], denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    averageAudioNetworkJitter?: Duration;
    /**
     * Average estimated bandwidth available between two endpoints in bits per second.
     */
    averageBandwidthEstimate?: number;
    /**
     * Average duration of the received freezing time in the video stream.
     */
    averageFreezeDuration?: Duration;
    /**
     * Average jitter for the stream computed as specified in [RFC 3550][], denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    averageJitter?: Duration;
    /**
     * Average packet loss rate for stream.
     */
    averagePacketLossRate?: number;
    /**
     * Ratio of the number of audio frames with samples generated by packet loss concealment to the total number of audio frames.
     */
    averageRatioOfConcealedSamples?: number;
    /**
     * Average frames per second received for all video streams computed over the duration of the session.
     */
    averageReceivedFrameRate?: number;
    /**
     * Average network propagation round-trip time computed as specified in [RFC 3550][], denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    averageRoundTripTime?: Duration;
    /**
     * Average percentage of video frames lost as displayed to the user.
     */
    averageVideoFrameLossPercentage?: number;
    /**
     * Average frames per second received for a video stream, computed over the duration of the session.
     */
    averageVideoFrameRate?: number;
    /**
     * Average fraction of packets lost, as specified in [RFC 3550][], computed over the duration of the session.
     */
    averageVideoPacketLossRate?: number;
    /**
     * UTC time when the stream ended. The DateTimeOffset type represents date and time information using ISO 8601 format and is always in UTC time. For example, midnight UTC on Jan 1, 2014 is 2014-01-01T00:00:00Z. This field is only available for streams that use the SIP protocol.
     */
    endDateTime?: Date;
    /**
     * Indicates whether the forward error correction (FEC) was used at some point during the session. The default value is null.
     */
    isAudioForwardErrorCorrectionUsed?: boolean;
    /**
     * Fraction of the call where frame rate is less than 7.5 frames per second.
     */
    lowFrameRateRatio?: number;
    /**
     * Fraction of the call that the client is running less than 70% expected video processing capability.
     */
    lowVideoProcessingCapabilityRatio?: number;
    /**
     * Maximum of audio network jitter computed over each of the 20 second windows during the session, denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    maxAudioNetworkJitter?: Duration;
    /**
     * Maximum jitter for the stream computed as specified in RFC 3550, denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    maxJitter?: Duration;
    /**
     * Maximum packet loss rate for the stream.
     */
    maxPacketLossRate?: number;
    /**
     * Maximum ratio of packets concealed by the healer.
     */
    maxRatioOfConcealedSamples?: number;
    /**
     * Maximum network propagation round-trip time computed as specified in [RFC 3550][], denoted in [ISO 8601][] format. For example, 1 second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is the time designator, and 'S' is the second designator.
     */
    maxRoundTripTime?: Duration;
    /**
     * The OdataType property
     */
    odataType?: string;
    /**
     * Packet count for the stream.
     */
    packetUtilization?: number;
    /**
     * Packet loss rate after FEC has been applied aggregated across all video streams and codecs.
     */
    postForwardErrorCorrectionPacketLossRate?: number;
    /**
     * Average duration of the received freezing time in the video stream represented in root mean square.
     */
    rmsFreezeDuration?: Duration;
    /**
     * UTC time when the stream started. The DateTimeOffset type represents date and time information using ISO 8601 format and is always in UTC time. For example, midnight UTC on Jan 1, 2014 is 2014-01-01T00:00:00Z. This field is only available for streams that use the SIP protocol.
     */
    startDateTime?: Date;
    /**
     * The streamDirection property
     */
    streamDirection?: MediaStreamDirection;
    /**
     * Unique identifier for the stream.
     */
    streamId?: string;
    /**
     * Codec name used to encode video for transmission on the network. Possible values are: unknown, invalid, av1, h263, h264, h264s, h264uc, h265, rtvc1, rtVideo, xrtvc1, unknownFutureValue.
     */
    videoCodec?: VideoCodec;
    /**
     * True if the media stream bypassed the Mediation Server and went straight between client and PSTN Gateway/PBX, false otherwise.
     */
    wasMediaBypassed?: boolean;
}
export function serializeMediaStream(writer: SerializationWriter, mediaStream: MediaStream | undefined = {} as MediaStream) : void {
        writer.writeEnumValue<AudioCodec>("audioCodec", mediaStream.audioCodec);
        writer.writeNumberValue("averageAudioDegradation", mediaStream.averageAudioDegradation);
        writer.writeDurationValue("averageAudioNetworkJitter", mediaStream.averageAudioNetworkJitter);
        writer.writeNumberValue("averageBandwidthEstimate", mediaStream.averageBandwidthEstimate);
        writer.writeDurationValue("averageFreezeDuration", mediaStream.averageFreezeDuration);
        writer.writeDurationValue("averageJitter", mediaStream.averageJitter);
        writer.writeNumberValue("averagePacketLossRate", mediaStream.averagePacketLossRate);
        writer.writeNumberValue("averageRatioOfConcealedSamples", mediaStream.averageRatioOfConcealedSamples);
        writer.writeNumberValue("averageReceivedFrameRate", mediaStream.averageReceivedFrameRate);
        writer.writeDurationValue("averageRoundTripTime", mediaStream.averageRoundTripTime);
        writer.writeNumberValue("averageVideoFrameLossPercentage", mediaStream.averageVideoFrameLossPercentage);
        writer.writeNumberValue("averageVideoFrameRate", mediaStream.averageVideoFrameRate);
        writer.writeNumberValue("averageVideoPacketLossRate", mediaStream.averageVideoPacketLossRate);
        writer.writeDateValue("endDateTime", mediaStream.endDateTime);
        writer.writeBooleanValue("isAudioForwardErrorCorrectionUsed", mediaStream.isAudioForwardErrorCorrectionUsed);
        writer.writeNumberValue("lowFrameRateRatio", mediaStream.lowFrameRateRatio);
        writer.writeNumberValue("lowVideoProcessingCapabilityRatio", mediaStream.lowVideoProcessingCapabilityRatio);
        writer.writeDurationValue("maxAudioNetworkJitter", mediaStream.maxAudioNetworkJitter);
        writer.writeDurationValue("maxJitter", mediaStream.maxJitter);
        writer.writeNumberValue("maxPacketLossRate", mediaStream.maxPacketLossRate);
        writer.writeNumberValue("maxRatioOfConcealedSamples", mediaStream.maxRatioOfConcealedSamples);
        writer.writeDurationValue("maxRoundTripTime", mediaStream.maxRoundTripTime);
        writer.writeStringValue("@odata.type", mediaStream.odataType);
        writer.writeNumberValue("packetUtilization", mediaStream.packetUtilization);
        writer.writeNumberValue("postForwardErrorCorrectionPacketLossRate", mediaStream.postForwardErrorCorrectionPacketLossRate);
        writer.writeDurationValue("rmsFreezeDuration", mediaStream.rmsFreezeDuration);
        writer.writeDateValue("startDateTime", mediaStream.startDateTime);
        writer.writeEnumValue<MediaStreamDirection>("streamDirection", mediaStream.streamDirection);
        writer.writeStringValue("streamId", mediaStream.streamId);
        writer.writeEnumValue<VideoCodec>("videoCodec", mediaStream.videoCodec);
        writer.writeBooleanValue("wasMediaBypassed", mediaStream.wasMediaBypassed);
        writer.writeAdditionalData(mediaStream.additionalData);
}
// tslint:enable
// eslint-enable
